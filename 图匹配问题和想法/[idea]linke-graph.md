#  linked-graph

[TOC]





## 针对噪声点和图结构的问题

- 具体解决图网络输入的问题

  目前网络是通过将两个图前后输入同一个GNN中然后得到匹配，会导致网络无法得到两个图之间的相似信息。

  PCA的工作提出了将目标域按照相似度变换到源域，进行拼接后输入一个GNN，该方法可能会造成过渡平滑。

## Related work

### Outlier的匹配相关工作

图匹配的outlier定义为源graph中不与目标graph匹配的节点。outlier无法从单个graph中确定，而是要通过两个graph的联合信息确定。



网络对outlier的处理上： 网络需要对输入的两个graph同时进行处理，而不是依次单独处理。首个深度网络GMN[1]将深度网络引入图匹配问题中用于特征的embedding，然而没有将两个graph**联合输入网络**中，PCA-GM[2]将把目标域的特征按**相似度线性变换**后拼接入源域特征中，但这种直接的线性变换可能会导致影响节点特征的非线性关系，从而导致过度平滑。BBGM只通过将单个graph依次输入共享权重GNN中，无法让源图在forward中学习到目标图的信息。



在后处理阶段对outlier的处理： 图匹配问题要满足**一一匹配**的约束，即每个节点的匹配可能性求和为1。传统计算的Hangrain算法由于不能求梯度而无法作为网络训练的匹配求解算法。PCA-GM, DQGM[3]使用可求导的sinkhorn迭代求解匹配，但是由于sinkhorn会让所有节点满足一一匹配约束，因此同时也会让**outlier的与目标域的匹配可能性求和为1**，从而无法被剔除。



### 图匹配问题转化为分类问题

- 可以将图匹配转化为节点分类问题。 Tao等人[4]直接将两个图结构构造成associate graph，考虑每一个边之间的关系。计算复杂度为$O((N_e*M_e)^2)$。然而

<img src="image-20211126223752547.png" alt="image-20211126223752547" style="zoom:33%;" />

- 而我们直接可以将两个图直接连接起来，构造link graph，此时可以更好地分理出outlier，并且计算复杂度为$O((N_v+M_v)^2)$， 当节点的数量增加时，该方法效率会更加高。 

  <img src="image-20211126224523002.png" alt="image-20211126224523002" style="zoom:27%;" />

## motivation



- 针对outlier的特性，我们应该考虑让网络能够同时处理两个图，而不是分别进行输入。下图为前人的工作，GNN之间虽然是共享权值，但是在forward过程中是无法得知目标图的信息，这导致outlier的区分度仅仅依靠单个图上的特征分布决定，而无法通过两个图的相互关系得到。我们的目的：

1. 针对让网络剔除outlier的问题，将两个图同时输入网络，让网络能够学习到两个图的信息。



<img src="image-20211130092651037.png" alt="image-20211130092651037" style="zoom:33%;" />



## Method



<img src="image-20211126222350440.png" alt="image-20211126222350440" style="zoom:33%;" />

- 如上图所示，将两个网络首先计算节点相似度，然后生成对应的连接边，构建一个包含两个图的连接图linked graph。将连接图输入到图生成网络中，输出的是包含了改进后的各个单图**独立边**结构和求解匹配的**匹配边**，并且对outlier的边进行抹除，后处理中通过检测孤立节点从而剔除outlier。
- 该方法将图匹配问题转化为图结构生成问题，不仅仅让网络求解匹配关系，同时还对图的结构进行重生成，让图的结构更加一致。

#### Loss

1. 匹配边的分类Loss：将两个图之间的**匹配边**$\hat Y_e$进行交叉熵。$L = -Y_eln(\hat Y_e)$
2. 图结构一致性Loss：用匹配关系作为监督，令两个图之间的结构更加一致。$L = ||\hat Y_s - X\hat Y_tX^T||_2$
3. outlier Loss：outlier的应该是孤立点，减少边节点$\hat Y_e$的Loss。$L = \sum_{Y_e\in Y_{outlier}}(1-\hat Y_e))$ 

## 贡献点

1. 将图匹配问题转化为图结构生成问题，并构建连接图求解问题。
2. 对图匹配中的噪声点进行定义，并通过检测生成图中的孤立节点剔除噪声点。
3. （希望）在带有噪声的图匹配问题中效果比已有方法要好（F1>60%）





## 未来可以提升的点

- 生成的匹配边是全连接图，感觉会也导致求解困难。要解决全连接图的求解复杂度：使用全连接边的图会增加求解空间的复杂度。 因此需要先验策略减少生成的边缘。

计算梯度反传，当匹配矩阵的forward得到的值比较小的时候，我们可以认为他跟对应节点之间的关系较小，反传参数的值也比较小。可以直接删除对应的边，从而减少计算量。

## 目前的不足

1. 未能进行显式的一一匹配约束，但是DGMC的工作表明不一定需要进行匹配的约束。







## Code visulaization

<img src="image-20211129112719159.png" alt="image-20211129112719159" style="zoom:33%;" />

A_l matrix

![image-20211129112829266](image-20211129112829266.png "image-20211129112829266")

x_l 





## implementation
<img src="image-20211129162454823.png" alt="image-20211129162454823" style="zoom:50%;" /><img src="image-20211129162508412.png" alt="image-20211129162508412" style="zoom:50%;" />





Adjancey off-blance

<img src="image-20211129193145271.png" alt="image-20211129193145271" style="zoom:50%;" />

S_L的效果不理想 mean：17%

S_0的效果反而挺好： 

|      | aerop | bicyc | bird  | boat  | bottl | bus   | car   | cat   | chair | cow   | dinin | dog   | horse | motor | perso | pot   | sheep | sofa  | train | tv    | mean    |
| ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ------- |
| S_0  | 24.53 | 56.06 | 43.81 | 56.55 | 83.46 | 81.29 | 69.34 | 60.79 | 33.04 | 52.18 | 75.66 | 50.94 | 61.36 | 39.76 | 42.08 | 94.85 | 52.46 | 84.37 | 90.70 | 79.96 | 61.6595 |
| S_L  | 8.2   | 16.5  | 14.1  | 16.8  | 19.5  | 24.8  | 17.5  | 11.2  | 17.3  | 12.5  | 23.1  | 11.9  | 13.1  | 17.9  | 11.3  | 27.5  | 13.1  | 14.5  | 31.5  | 31.5  | 17.7    |
|      |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |         |

在







![image-20211130171601124](image-20211130171601124.png)

只使用一个gnn生成match结果：

output aerop bicyc bird  boat  bottl bus   car   cat   chair cow   dinin dog   horse motor perso potte sheep sofa  train tvmon mean

S0: 39.7  50.9  51.2  58.8  83.0  82.2  75.2  61.6  33.5  60.0  79.8  58.1  65.2  45.0  52.4  89.8  55.0  79.2  87.5  83.0  64.6 

SL: 36.2  44.1  48.4  55.4  81.2  80.6  64.9  50.4  32.0  47.8  81.7  50.8  49.0  40.9  38.5  90.3  49.1  71.3  82.9  82.2  58.9 



这个不算很差，修改了基本可以work， 但是问题：match边和图边的不平衡，由左上图看出当match的正确率比较高的时候，self-edge的值相对较小，容易造成不平衡，如何去解决这个不平衡问题？或者说这个不平衡和精度之间是否是天然矛盾的？



#### 实验11/30-1

取消了节点特征生成各自图的归一化后，效果反而下降了。linked-graph的边权重不平衡没有减缓。



|output| aerop|bicyc|bird |boat |bottl|bus  |car  |cat  |chair|cow  |dinin|dog  |horse|motor|perso|potte|sheep|sofa |train|tvmon|mean|
| ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ------- |
|S0| 14.3 |26.7 |18.0 |51.9 |72.8 |82.6 |44.3 |26.8 |25.4 |20.2 |72.7 |21.8 |26.3 |29.1 |18.2 |93.5 |22.5 |58.6 |89.0 |78.2 |44.6 |
|SL| :13.2 |25.7 |18.5 |51.7 |62.6 |81.1 |43.3 |24.0 |24.8 |19.6 |71.3 |21.2 |24.6 |29.7 |16.3 |90.8 |21.6 |56.7 |86.5 |77.6 |43.0 |

#### 实验11/30-2

节点dim=-1归一化后加转置，效果一般50起步，SL低于S0

| output | aerop | bicyc | bird | boat | bottl | bus  | car  | cat  | chair | cow  | dinin   | dog  | horse | motor | perso | potte | sheep | sofa | train | tvmon | mean |
| ------ | ----- | ----- | ---- | ---- | ----- | ---- | ---- | ---- | ----- | ---- | ------- | ---- | ----- | ----- | ----- | ----- | ----- | ---- | ----- | ----- | ---- |
| S0     | 29.5  | 38.7  | 40.4 | 57.9 | 80.6  | 82.4 | 73.0 | 58.9 | 32.0  | 54.4 | 79.94.7 | 56.2 | 78.2  | 85.9  | 80.8  | 60.8  |       |      |       |       | 61.2 |
| SL     | :28.5 | 31.1  | 38.1 | 59.3 | 77.7  | 77.7 | 61.7 | 54.5 | 31.0  | 48.7 | 77.9    | 49.8 | 52.8  | 35.8  | 34.3  | 93.2  | 50.7  | 76.7 | 85.1  | 78.0  | 58.2 |



#### 实验11/30-3

节点dim=-1归一化后加转置/2

| output | aerop | bicyc | bird | boat | bottl | bus  | car  | cat  | chair | cow  | dinin   | dog  | horse | motor | perso | potte | sheep | sofa | train | tvmon | mean |
| ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ------- |
|S0| 37.8 |38.4 |44.9 |65.7 |84.1 |82.9 |75.5 |64.5 |29.7 |56.4 |78.2 |54.1 |63.5 |43.6 |43.5 |95.1 |61.3 |82.8 |91.5 |82.9 |65.6|
|SL| :33.7 |37.2 |39.5 |61.9 |82.6 |75.4 |63.8 |53.5 |29.7 |46.4 |74.0 |48.4 |50.8 |38.6 |32.0 |95.0 |52.5 |81.6 |85.0 |79.1 |58.9|

#### 实验 11/30-4  no_detach()

不切断S0的计算图，结果一般比切断的要好一些

| output | aerop | bicyc | bird | boat | bottl | bus  | car  | cat  | chair | cow  | dinin | dog  | horse | motor | perso | potte | sheep | sofa | train | tvmon | mean |
| ------ | ----- | ----- | ---- | ---- | ----- | ---- | ---- | ---- | ----- | ---- | ----- | ---- | ----- | ----- | ----- | ----- | ----- | ---- | ----- | ----- | ---- |
| S0     | 34.1  | 50.4  | 47.6 | 63.0 | 84.3  | 81.0 | 74.2 | 65.2 | 37.2  | 56.4 | 86.6  | 61.9 | 64.2  | 52.8  | 51.0  | 93.7  | 58.9  | 80.1 | 87.2  | 82.4  | 65.6 |
| SL     | :29.2 | 43.2  | 44.9 | 57.6 | 84.3  | 78.1 | 61.1 | 55.1 | 33.1  | 46.5 | 76.3  | 53.0 | 53.0  | 49.3  | 38.8  | 92.3  | 50.5  | 73.5 | 79.5  | 78.5  | 58.9 |

#### 实验 11/30-5 add_S0SL



精度有了很好的提升，比较work，但是不sota

| output | aerop | bicyc | bird | boat | bottl | bus  | car  | cat  | chair | cow  | dinin | dog  | horse | motor | perso | potte | sheep | sofa | train | tvmon | mean |
| ------ | ----- | ----- | ---- | ---- | ----- | ---- | ---- | ---- | ----- | ---- | ----- | ---- | ----- | ----- | ----- | ----- | ----- | ---- | ----- | ----- | ---- |
| S0   | 36.9 | 55.8 | 50.5 | 59.5 | 81.8 | 84.5 | 82.2 | 70.0 | 34.4 | 56.3 | 81.9 | 56.5 | 68.7 | 53.4 | 49.8 | 91.8 | 60.5 | 89.2 | 86.7 | 79.0 | 67.3 |
| SL   | :37.0 | 55.9 | 50.8 | 59.8 | 81.7 | 84.3 | 82.2 | 70.0 | 34.5 | 56.3 | 81.9 | 56.4 | 68.6 | 53.7 | 49.8 | 91.9 | 60.5 | 89.2 | 86.8 | 78.9  | 67.3 |





#### tablet

| method                       | epoch | accuracy  | loss                      | other  |
| ---------------------------- | ----- | --------- | ------------------------- | ------ |
| S0+SL GAC_my nodetah         | 15    | 67.3      | S0loss,SLloss outlierloss |        |
| S0+SL GAC_my nodetah batch32 | 10    | 71.2      | S0loss,SLloss outlierloss |        |
| S0+SL GAC_my nodetah batch64 | 10    | 72        | S0loss,SLloss outlierloss |        |
| no detach                    | 15    | 65.6/58.9 | S0loss,SLloss outlierloss |        |
| dgmc                         | 20    | 73        | S0loss,SLloss             | spline |
| spline-gnn                   | 20    | 63        | S0loss                    |        |



增加batch size可以增加精度，目前只是做了生成边的模型，并且还需要将S0加上去（生成模型）相当于残差部分，有一点效果，但是提升不算大，还没有超过dgmc。

下一步计划用于生成原来图上的结构， 用于让网络更加容易做匹配。

要用groundtruth监督图的结构，然后再用这些结构去跑匹配，最后剔除噪声点。



<img src="image-20211202174736418.png" alt="image-20211202174736418" style="zoom:70%;" />





<img src="image-20211202174805880.png" alt="image-20211202174805880" style="zoom:67%;" />





![image-20211202175300710](image-20211202175300710.png)

通常target图的节点特征强度会大一点？：代码bug

ht，hs做了归一化之后效果好很多了，说明特征生成的图结构还是要做归一化才生成linked-graph比较好。

Loss都是下降的，但是精度还是卡住了，说明网络存在过拟合的可能。







![image-20211203222442752](image-20211203222442752.png)

如何让网络将原本的噪声去除？

如果一开始的判断就出错了，网络如何在后续的迭代更新节点特征中把错误的信息重新判断到？





![image-20211210160351802](image-20211210160351802.png)

![image-20211210160416430](image-20211210160416430.png)

要让生成网络做的任务是预测边结构，因此要有一个合理的方式生成图的结构。首先不能让原本的匹配结果更加平滑，我们的目标就是要根据松弛的初始解得到一个更加精确的离散解，网络在求解离散解的时候效果不一定很好，但是网络的拟合能力比较强的，根据这个对所有的节点做分类。



过拟合问题：初始的解已经无法再继续优化了，这时候应该有个减缓机制，防止网络过拟合



网络应该去预测噪声，让让这个模块接近离散解，同时又可以用参数做拟合。

通过让网络生成的方式，能够让网络补全初始解中未能发掘的匹配对，如下图所示：

左图为初始解生成的linked-graph，其中受噪声干扰某些gt的概率比较低，通过网络生成右图的连接边，可以获得更接近gt的匹配结果.<img src="image-20211210202947945.png" alt="image-20211210202947945" style="zoom:40%;" /><img src="image-20211210203006085.png" alt="image-20211210203006085" style="zoom:40%;" />

<img src="image-20211210170403794.png" alt="image-20211210170403794" style="zoom:50%;" /><img src="image-20211210170519074.png" style="zoom: 50%;" />

<img src="image-20211210204245664.png" alt="image-20211210204245664" style="zoom:50%;" />



但是使用relu会造成上限没有限制，会让一些结果变得很小，使用sigmiod反而会让梯度消失。

尝试使用layernorm去平衡分布，让预测值范围更小。



<img src="image-20211210202230311.png" alt="image-20211210202230311" style="zoom:50%;" /><img src="image-20211210202611233.png" alt="image-20211210202611233" style="zoom:50%;" />

生成的图尾部出现模糊情况，不清楚为什么。





在初始解噪声较大的情况下，优化效果也不是很好。

<img src="image-20211210202505870.png" alt="image-20211210202505870" style="zoom:50%;" /><img src="image-20211210204314564.png" alt="image-20211210204314564" style="zoom:50%;" />







<img src="image-20211210220411031.png" alt="image-20211210220411031" style="zoom:50%;" /><img src="image-20211211162606754.png" alt="image-20211211162606754" style="zoom:50%;" /><img src="image-20211211162647667.png" alt="image-20211211162647667" style="zoom:50%;" />



## 过拟合问题

网络主要由两个结构组成：

1. emb = GNN(x,A) 学习特征初始解
2. AL = GAE(x,A) 优化特征解



过拟合的情况认为第一个网络训练的效果太好了，已经没有过多优化空间给GAE，所以要给GAE的优化空间要更大。



采取的措施：首先训练GAE，然后再训练GNN。 做了一次实验后发现，训练好的GAE精度可以将S0的30%提升到70%，但是一开始训练GNN，所有的精度都掉到20%了，相当于随机初始化，而且效果更差，可视化结果如下，gnn输出的预测差异太大了，

<img src="image-20211214200629098.png" alt="image-20211214200629098" style="zoom:50%;" />



## 讨论结果

1. GNN是否有效[^如何更加鲁棒地表示图结构的嵌入]？怀疑特征是根据节点特征就可以做好分类，而不需要GNN再做特征表达。

2. GAE的有效性？GAE的形式和attention很像，有没有方法可以更好的学习到整个图的相似性，而不是仅仅类attention。；

3. 大规模数据集的用处

4. 如何用上iteration提升精度

5. outlier数量比较多的时候精度如何？

6. 如何设计使用传统迭代去输出结果，这应该是一个比较自然的过程。

   





1. GNN的有效性：去除了SplineGNN之后精度下降了很多，但是在初始解噪声比较大的时候还是可以获得比较好的还原的。可能是模型的参数量不够大，试验后的结论是好的GNN确实是有效的，可以学习到每个节点在图上对应的位置。

   | GNN                                                          | GAE  | acc   |
   | ------------------------------------------------------------ | ---- | ----- |
   | √                                                            | √    | 72    |
   | x(直接使用图像的feature作为节点特征)                         | √    | 56.73 |
   | x(让节点只和自己相连，切断所有的边，输入到GNN中得到emb feature) | √    | 50    |
   | x(直接对image特征相似度做softmax作为S0)                      | √    | 56.45 |
   | x                                                            | x    | 42    |
   
   

![](image-20211212223102001.png)
<img src="image-20211212223504817.png" alt="image-20211212223504817"  />

<img src="image-20211214175221552.png" alt="image-20211214175221552" style="zoom:50%;" /><img src="image-20211214195914840.png" alt="image-20211214195914840" style="zoom:50%;" /><img src="image-20211214220512014.png" alt="image-20211214220512014" style="zoom:50%;" />

存在右图的这种全部识别到一个特征的情况，应该要减少softmax的规范化。但是精度也没有明显的提升，估计要调学习率

![image-20211214225704182](image-20211214225704182.png)



2. GAE的效果，如何证明GAE是有效的？只用一个

3. 大规模数据集，使用superglue的特征点做特征提取。





4. 使用迭代的方法精度并没有提升，稍微掉点了（69%），感觉网络参数还是太少了了，导致没办法学习到泛化性。



[^如何更加鲁棒地表示图结构的嵌入]: https://arxiv.org/abs/2010.12811

## 考虑连接图detach的设计，以及不加入权重的设计



## 收集检测精度低的效果图





## 下游任务的问题

作为图匹配算法，主要针对的问题是图片的语义匹配上，语义匹配中没有固定的图片结构，所以是人为定义语义结构，但是在蛋白质生物领域上，还是有客观存在的图结构的，这时候再去改变图结构就显得不是很好。





## 改变生成器的结构

![image-20211229152338000](image-20211229152338000.png)

直接使用gae效果并不好，几乎很难学到东西，自己写的又过于简单，对精度提升很小。精度不高的原因：网络参数太少了，做生成式模型的效果太差。



提高参数数量，对生成器设置合理的结构



在生成器经过了图的聚合之后，所有的值会相加，从而导致数值过大，求内积之后每个图的权重就很大，应该要求余弦距离，保证所有的值都在-1，1之间。



不监督S0的情况下，S0的检测精度比较低，但是最终结果依然会比较高。 米7

但将S0做detach之后，结果就比较低了。



以上的实验结果说明了spline具有较强的拟合能力，即使不直接监督最终结果，但是spline依然会通过配合最终输出得到一个较好的效果。目前来看spline的精度上限在73，而后续的提精度拟合重任则放在了生成器上。



但是对于生成器来说，输入的是73正确率的图结构，就会出现正负样本分配不平衡的问题，如何去解决这个呢？

1. 首先增加生成器的结构复杂度：用spline做生成器？
2. 动态调节正负样本的分配

## 设计一个判别器去对匹配结果打分

目标函数最大值不一定代表实际上的匹配，实际上匹配具有噪音，并且

