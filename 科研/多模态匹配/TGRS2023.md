### Learning to find the best math between the Optical and SAR patches.

这个题目里面没有提到用地理信息，但是我们的贡献点里面有增加地理信息来优化匹配选项。

 

 

## **Abstract**

 

Giving an SAR image patch, how to find the best match from the grided Optical reference database plays a key role to the analysis of the remote sensing data. (Claims the challenges) 

 

This task is challenging due to the great gap between the modality between SAR and Optical images and the arbitrary location of the query images.

 

However, since the great gap between the modality between SAR and Optical images, it is hard to directly establish the correspondent base on similarity metric. Furthermore, the arbitrary location of the query images breaks the alignment assumption of the one-to-one retrieval setting. To address these challenges, we propose the coarse-to-fine framework construct with the retrieval-based coarse search and graph refinement module to match the SAR queries with the optical reference patches. We utilize the Wasserstein discrepancy to between distribution of SAR and Optical images. 

## **Introduction**

 

 

Matching the patches from different modality is a challenging task.(why hard?) The optical image is captured by the optical sensor, which is similar to the natural sensing of human being. On the other side, the SAR sensor catches the geometry of the buildings, which including the structure information. 

 

There are two limitations:

 

 

Problems：

\1. the gap between the feature distribution from cross-modality

\2. the arbitrary of the query image lead the position shift of the reference image.

 

 

Solutions:

\1. propose the Wasserstein discrepancy to measure the gap between two distributions.

\2. propose the location aware graph network to refine the retrieval prediction. 

 

### **Huge gap between two modalities:** 

在将一张SAR图像和数据集的大图进行匹配时，通常使用基于对比学习的方法，该方法训练一个特征提取网络对输入图像映射到相似度量特征空间，相同区域的图像能够得到相似的特征，并基于特征之间的相似度进行检索，得到对应目标特征。相比于传统的单模态图像检索任务，由于光学图像与 SAR 图像在成像机理上有较大的不同：光学图像反映的是地物目标可见光波段的信息，而SAR图像的信息是地物目标对雷达波束的反映，SAR 图像灰度值主要受地物目标的后向散射的影响。光学图像与SAR 图像的模态差异导致二者的颜色信息、纹理信息等对检索任务十分重要的信息都存在着显著的差异，这种差异导致了两者的特征分布不相同，难以直接使用相似度度量的方法进行特征的检索。目前跨模态特征检索通常使用通道替换或者样本增强的方法构建两种模态之间的共有特征，但是这种启发式的增强方法只是改变了图像的表观特征，网络自身并没有减少到不同模态之间的特征分布差异。

 

 

（传统图像增强的方式泛化性较强，不需要额外训练样本）

 

 

Matching a SAR image patch to Optical databases, the recent common solutions are using contrastive learning to embed the images to similarity space, which the image of same region have a similar global feature

 

 

### **Arbitrary location of the queries:** 

在实际匹配任务中，不同模态的图像来自于不同的传感器，拍摄同一区域的图像存在位置、尺度的差异，从而导致图像之间不是完全对齐的。这种查询图像和检索图像之间存在不确定的位置偏移，导致在基于检索过程中，即使在同一场景中特征还包含由于位置偏移造成的度量差异。由于检索数据库是密集排列的包含丰富地理（元）信息图像集，如何在利用地理信息和密集滑窗的条件优化匹配流程成为值得研究的挑战。

 

针对以上的挑战，我们提出了一下的贡献：

\1. 针对由于传感器不同导致图像之间模态的差异，我们使用Wasserstein度量模态之间的差异，并使用对抗学习的方法减少模态之间的差异。

 

 

### **Contribution**

\1. We propose a Wasserstein discrepancy to represent the different between cross-modal feature, and combine the adversarial training strategy with contrastive learning to reduce the gap between Optical and SAR image.

\2. We propose a graph refinement by build graph representation for the reference images. 

\3. We propose a coarse-to-fine retrieval-based matching framework for cross-modal remote sensing image patches matching.

 

 

 

 

## **Related Works**

这个任务设计跨模态特征表达（1）， 基于检索的地理定位任务（2），reranking 方法（3） 

Numerous methods have been developed for contented-based retrieval 

 

###### **1. Contented-based Retrieval**

4

 

###### **2. Cross-modality embedding method**

针对跨模态特征提取任务，（Reid）方法，使用随机通道的增强训练方法， DCMHN针对SAR和光学图像的差异，提出了使用图像transformation的方法在网络训练阶段增强网络对不同模态的提取特征的鲁棒性。Xmod方法使用了生成器模拟中间模态的图像，通过在训练阶段对特征在不同模态的表达进行泛化。

###### **3. reranking****的优化方法**

在计算初步检索结果后，对ranking进行重排序能够提升匹配的精度。目前的reranking主要包括通过对检索前k个结果的global feature的进行相似度的挖掘，这类方法只利用到了相似度的信息，为能获取更多的元信息辅助优化流程。另一类的方法主要对检索结果进行局部特征的提取，通过计算局部特征的相似度进行重排序。这一类方法需要花费局部特征的提取计算成本，消耗更多的特征储存空间，在大规模数据检索中实现性不足。还有一类基于深度学习的方法，首先将初步检索结果的特征输入网络中，让网络学习到重排序的特征分布。这一类方法需要在特征进行初步排序后重新训练对应的网络，和特征提取网络分开，没有做成端到端，增加了网络框架的训练成本。针对以上方法的不足，我们提出了coarse-to-fine的端到端图像匹配框架，在一次训练过程中完成对基于检索的特征提取网络和基于优化预测的重排序网络的训练，并结合GPS地理信息提升网络预测模块的精度。

 

 

## **Methodology**

 

 

### **Problem formulation**

Giving query, how to find the SAR query from a large size aerial optical image. A common solution is to divide the large aerial image to small patches , then retrieval the best match of the query image. The retrieval-based method assume that the queries and the references have the same metric and can retrieval by the similarity of their feature. How, the great gap between the optical and SAR image, caused by the difference of the 

 

 

 

In the proposed method, we introduce the Wasserstein discrepancy to explicitly model the shape constraints, as well as a CNN shape regularizer to strengthen the embedding of shape features 

  

### **Establish the coarse-level retrieval**

 

Wasserstein adversarial training and triplet loss to reduce the modal discrepancy.

The difference between the SAR and optical image leads the difficult to 

 

 

Graph prediction refinement

 

After establishing coarse ranking based on the similarity metric, 

The retrieval ranking result is After the coarse search 

 

 

 

 

## Experiments

 

\1. SOTA comparison

\2. Ablation study 

\3. Retrieval result visualization

\4. Analysis of the Wasserstein adv and the class adv strategy. 

 

 

 

 

 

传统的视觉检索方案

传统的视觉检索方案通常将具有GPS标注的卫星地图通过滑窗裁切成小patch，通过检索的方式找到相似度最大的图像作为匹配的

 

In the image retrieval-based scheme, the large satellite map is first split into small image patches to construct the reference database. Given a query SAR image, the common solution is to find the most similar patch from the reference database based on the visual appearance. And the GPS-tag of the retrieved image is regarded as the query camera’s location. In this scheme, the GPS information of the reference is only used for location assignment, but not for improving search accuracy. We used the GPS information to build the graph to refine the retrieval accuracy. 

 

 

 

目前不同模态图像之间的检索问题，通常使用特征提取器将输入的图像嵌入到特征向量度量空间。The visual of query image is different from the reference images, which lead to difference between the feature distribution. These visual difference leads to difficulty metric to the similarity to the feature discrepancy. There are it is important to reduce the difference between the query and reference domain(modality). 

Considering that the feature of the query image patches is not aligned to the same region of the reference optical images. The feature can not calculate the direct distance between the positive samples. We utilize the Wasserstein discrepancy to measure the gap between the query and reference. 

The wass

 

---



 

 

The cross-modal retrieval between SAR and optical images. This is a challenge task because of the great gap of the visual imaging between the two different modalities. 

 

 

The supervised machine learning method provide a tractable statistic approach to retrieve the visual information from the image data.





The experimental results show show the important improve of the proposed method. We design the feture membedding method for the SAR-optical cross-modality image retrieval task. Consider the position information provide by the image meta data, the GNN refinment module is proposed to deal with the localization informnation.

 

dataset



\textbf{Optical Patch Database.} Given an optical map of the city, our objective is to match a SAR query in this map by matching it with reference patches cropped from this map. To guarantee that any query can match the target from the patches, the reference patches must provide seamless coverage of the map. As shown in Fig.~\ref{fig:dataset} (3), the reference patches are cropped at the grid without overlap. The size of the optical patches is $200 \times 200$ pixel.

\textbf{SAR Patch Quires.}  The SAR strips are in arbitrary locations captured by the UAV, which are not absolutely aligned with the optical map and have different sizes. We design two types of SAR patches from these stripes: aligned patches and arbitrary patches. For the aligned patches setting, we first align the SAR stripes with the optical manually and crop the SAR patches which are aligned with the optical patches. The aligned SAR patches are assigned the same GPS tag with the corresponding optical patches, as shown in Fig.~\ref{fig:dataset}. The SAR patches in the boundary of the strip are cast away.









**selected** idx: 112,175,190, 268, ,653



refine select: 7, 10, 11, 175;  6, 14,30; 651, 734, 758, 







base

0,2,13,15,20,26,29,33,48,49,65,68,73,82,83,91,94,100,102,105,112,126,138,145,155,158,167,169,173,175,178,186,187,190,198,199,201,202,213,221,224,231,241,251,258,259,267,268,273,274

refine

0,7,10,11,13,14,15,20,27,29,33,48,57,61,63,65,68,69,73,77,80,81,82,91,97,100,101,105,112,113,116,119,120,121,125,128,129,131,138,141,144,155,168,173,175,178,182,185,190,192

**gnn**

results/gnn_samearea/gnn_same_posatten_posEmb_nodeTop10_edgeTop5/59_param.t experiments/gnn_same.json

0,2,13,15,20,26,29,33,48,49,65,68,73,82,83,91,94,100,102,105,112,126,138,145,155,158,167,169,173,175,178,186,187,190,198,199,201,202,213,221,224,231,241,251,258,259,267,268,273,274



**wd**

results/adv_same_wd/wd_drop05_vanilla/59_param.t 

experiments/adv_samearea_wd.json

0,13,15,20,31,48,65,73,77,78,83,91,94,95,97,102,105,107,113,125,126,128,131,137,138,143,145,158,159,165,172,173,176,178,185,186,198,199,208,215,219,221,224,240,243,251,258,259,266,267



**w/o project, w/o wd**

results/adv_same_wd_gnn/woWD_woProject_gnn/59_param.t experiments/adv_same_wd_gnn.json 

7,11,14,18,20,26,45,48,49,55,56,68,69,77,82,92,101,113,119,120,125,136,138,145,153,158,163,164,172,182,185,186,190,232,237,248,251,258,263,265,277,279,281,290,299,309,312,317,325,346



**wd bad**

results/adv_samearea/drop0/59_param.t experiments/adv_samearea.json 

0,11,15,20,22,29,31,44,63,89,95,101,105,125,126,128,131,137,143,153,158,159,167,173,185,186,194,201,212,215,221,231,241,255,257,259,264,274,285,287,288,290,292,293,294,297,298,299,304,307



unique: 

2,  26,  29,  33,  49,  68,  82, 100, 112, 155, 167, 169, 175, 187,190, 201, 202, 213, 231, 241, 268, 273, 274
