# 10.30talk with XueNan

### 确定大方向问题

目前研究方向的重心应该为outlier的去除，其次才是自监督。

outlier removal在传统图匹配方向研究的也不多，已知是王福东的ZAC。DeepLearning的outlier on graph几乎没有研究。

个人总结：大方向是没有问题的，而且深入做是有很多可以发现的点。问题的可做方向：outlier removal>self-supervised=graph generation

### 研究进度的问题

该问题还需要深入去思考，将整个大的任务（outlier removal）分成各个小的部分（如embedding space的分布，特征的提取是否有效），逐个攻破每一个小问题。把问题分解成类似二叉树的结构，首先解决每一个叶子节点，从而逐步解决到根节点，把问题解决掉。关键就是如何去划分每一个叶子节点问题。有时候大家的idea差不多，但是看问题的深度会影响能发的刊的级别（nerf是一个很好的例子）。

### 在针对具体问题思考方向的交流：

1. outleir和inlier的区别在哪里？

   在deep的特征下，outlier和inlier的object特征应该是相似的，是否有办法找到一个embedding space能够令outlier和inlier区分开来，相信以deep network的能力是能够做区分的，所以目前要对outlier和inlier的区分做建模。

2. 是否需要对outlier在目标方程中显式表达出来。在传统图匹配中目标方程为$\min_X （||A-X^TBX||^2 + ||PX||^2）$，这里没有考虑到outlier的项，是否应该加入一项考虑outlier的影响，比如$\min_X （||A-X^TBX||^2 + ||PX||^2+F(X_{outlier}）$？

   没有这个必要，不用想直接在目标方程中就解决outlier的问题，而是在具体操作中去建模embedding space.

3. 自监督的意义？

   自监督的优势应该是要学到有监督中给label学不到的内容，但是目前我做的方法在有监督上也不work，应该要更加重视有监督中为何不work的情况。

4. overfit的情况？

   有可能是自监督和有监督的差异，我这个自监督相当于是用affinity transform生成样本，实际上这个overfit问题就是data gap，生成的样本和实际匹配样本之间的差异是有的，导致自监督生成样本的任务过于简单。因此还是要在有监督的情况下测试我的方法是否work。

   

	### 实现上细节的讨论

1. 代码一定要保证正确
2. 在特征可视化中TSNE不一定有用，没必要过于关注TSNE的可视化结果
3. 方法有效性的测试还需要先考虑只有inlier的情况，先保证只有inlier的情况下work，再去做包含outlier的任务



### 新idea的讨论

![image-20211101105624467](C:\Users\HY Lee\AppData\Roaming\Typora\typora-user-images\image-20211101105624467.png)

可以先实现了，该方法在传统学习中有效，可以迁移到深度上看看网络的拟合能力。

