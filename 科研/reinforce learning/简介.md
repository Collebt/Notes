# Learning to play



state： 代表



用go做例子，用supervised做不一定好，因为reward是sparse的。

许多reward是没有定义的，很多时候action之后不一定由reward（可能什么都不会发生）





- chat-bot

  对话内容反馈机制是模糊的，人为指定规则，

- go

  reward是由比赛输赢决定的



## edifficulties of reinforcement

- reward delay









## outline

### Policy-based









### Value-based

