日期：2021.12.25
报告人：陈帅霖
记录人：张妍
论文：Masked Encoders are Scalable Vision Learners
问题：
（第3页）Discriminative和Generative模型的区别：
Discriminative model学习条件分布函数；Generative model生成联合概率分布。
（第10页）（Asymmetric MAE architecture）：
MAE中的非对称主要体现在encoder和decoder输入数据的非对称。Encoder的输入数据只有可见的（没有被mask的）patch，而decoder为了重建被mask的像素，必须将被mask的patch也输入进去。这个非对称的架构不仅可以减少encoder的计算量，而且可以避免encoder学习到重建像素的能力，而是让encoder更关注于全局语义的理解，这对于下游任务是更加有利的。
（第9页）文章提炼的关于什么使得视觉和语言在masked autoencoding不同的三个问题和解释是什么含义？
将masked tokens应用于图像上时，由于在卷积操作中存在感受野，在unmasked patch上进行卷积也会将masked patch的部分混淆进去。因此卷积网络是不适用的，而使用vision transformer。
语言和图像的信息密度是不一样的。语言是人类发明出的一种信息编码方式，它的信息密度较高，一句话中缺少一两个词就往往令人无法理解。而图像经过多次下采样后人还是可以理解图像的内容。因此相比于文本，图像需要更大的mask ratio。
Decoder在重建文本和图像中作用不同。在NLP中，一个单词就是一个语义实体，单词本身就是high-level的语义，因此BERT不需要decoder。而在CV中，作为重建目标的像素值本身是low-level的，也就是说模型的layer从浅到深需要学习low-high-low这样的特征，但是最后的low-level特征对于下游判别任务是没有帮助的，因此MAE需要用一个decoder来承担将抽象语义还原为像素的任务，并且在后续下游任务的fine tuning中将decoder丢弃。
（第15页）wall-clock time是社么意思？
对应CPU的时钟周期有CPU clock time；wall-clock指挂在墙上的钟，wall-clock time也就是现实世界的时间。
（第19页）为什么grid采样方式还原出来的图像还有网格型的灰色patch在里面？
模型在计算loss时没有包含未遮罩的patch，因此还原图像时是没有重新还原未遮罩的patch的，这些patch在结果图像中表现得比masked patch更加灰暗，视觉效果更差。
是否在遥感图像上尝试？
我在SpaceNet6上尝试了一下，直接用的网上公布的代码，没有改参数，但是训练出来没有什么效果。我觉得对于遥感图像，尤其是极化SAR图像，首先patch size需要改小一些，其次mask ratio也需要改小，因为遥感图像比较复杂，而且每个目标的尺寸也相对较小。
最后用于滤波的Swin-UNet的具体配置和训练时间如何？
这个Swin-UNet是个轻量级的架构，每个stage只有两个SWin block；patch size为4，window size为8。我用的数据只有1400张512x512的图像，跑了600个epoch，在bytedance上的两张卡跑完大概需要10个小时，两张卡的显存都快占满。
郭浩文：
可以尝试在可见的patch上加噪声，然后让模型预测原始的masked patch，因此来训练模型去噪的能力。

杨老师讲话：
培养好习惯
一个小小的好习惯能够在日后对人有深远的帮助。比如人每天刷牙多仔细地刷一会儿，长期下来口腔牙齿更能保持健康，在年老时也能正常进食。就比如说我们可以养成早睡早起的习惯，至少可以早起。每次认真听取组会报告，听不懂也提出自己的问题，日积月累就可以懂得更多，获得更多的思路。
要做出改变
虽然一般说很难改变一个人，尤其是成年人，但是人还是要做出改变、能够改变的。如果一个人在他人的劝诫下还是无动于衷，那么这个人只能说是不可教也。
做成一件事
我们在一个阶段至少要做成一件事，这样才能形成良性的反馈，不断激励我们去做下一件事。不能一件事做一会儿就放弃了，又去做别的事。比如我们本科生同学就要定一个目标，就要把毕业设计做好，第一件事做成了，之后的研究生阶段更能进一步出成果，做成一件又一件的事。