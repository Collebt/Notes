# python 的矩阵计算

**矩阵的基本属性**

ndarray.ndim 矩阵维度

ndarray.shape 矩阵的尺寸 返回值：tuple

求矩阵最大尺寸的维度尺寸：max(ndarray.shape)



## np.linalg

np.linalg.matrix_rank(A) #求rank(A)

np.linalg.det(A) det(A)

a.diagonal() #返回对角线元素

a.trace() #返回trace

eigenvalues,eigenvectors = np.linalg.eig(a)



 ##  多个矩阵相乘

**多个矩阵相乘不能用显式** `A*B*C`

np.dot(A,B) 和np.matmul(A,B)代表矩阵相乘（二维时表现相同），但只能有两个输入矩阵。



**多个矩阵相乘**

```python
X = A.dot(B).dot(C)
X = A @ B @ C
#没有matmul的属性
```



## 多维度的矩阵乘法

**np.dot:**

0D:dot=multiply/* 标量相乘

1D:求内积（inner product）`c = np.dot(a.T, b)`

2D:矩阵乘法，推荐使用matmul / @ 

3D:np.dot(a,b)

```python
a.shape=(a1,a2,a3,same_dim)
b.shape=(b1,b2,same_dim,b4)
ab = dot(a,b)
#ab.shape = (a1,a2,a3,b1,b2,b4)

c = dot(a,b)[a1,a2,a3,b1,b2,b4]
d = sum(a[a1,a2,a3,:]*b[b1,b2,:,b3])
#c=d
```

 

 

**np.matmul:**

D>2：最后两维看成是矩阵，前面是矩阵的集合，如果前面的无法广播，则会报错。(operands could not be broadcast together with remapped shapes



```python
np.dot(a,b)

a.shape=(a1,a2,a3,same_dim)

b.shape=(b1,b2,same_dim,b4)

# condiction:ai==b1|ai==1|bi==1 i=1,2…N-2

matmul(a,b).shape = (a1,a2,a3,b4)

#matmul(a,b)[a1,a2,a3,b4] = sum(a[k1,k2,a3,:]*b[k1,k2,:,b4])
```

 

dot和matmul在超出2D的情况下广播机制不相同，matmul可用在原本需要对矩阵进行for循环操作的情况。

 

## 几种矩阵乘法总结

```python
 x @  y     #多个矩阵相乘 

torch.mm() #二维矩阵乘法

torch.bmm() #三维，第一维是batch，无法广播

torch.matmul() #可支持多维，前面维度需要相同，可以广播

torch.dot() #可支持多维，前面维度不需要相同，为对应相乘
```



## 矩阵运算优化加速技巧

**技巧一**:一定要利用numpy的矩阵乘法dot和einsum。

- dot 二维矩阵乘法
- einsum 一般矩阵乘法,数据量大时两次einsum一次标量减法甚至快于一次einsum一次向量减法

**技巧二：避免大量重复调用numpy函数解决小规模问题**

- 能够使用numpy矩阵运算函数一次计算，则千万不要再使用for循环

**技巧三：优先对较低指标求和1**

- 需要大量求和运算的指标尽量放在第一位

**技巧四：使用ravel对矩阵一维化**

- ravel将多维数组一维化时避免拷贝，所以速度较快。相比之下，flatten一维化返回拷贝所以慢几个数量级，reshape(-1)一维化也可以避免拷贝，但是相比ravel要慢一些。

**技巧五：使用矩阵自运算替代运算后赋值**

- 自加、自减等运算要比运算后赋值要快，即 `a*=2`要快于`a=a*2`。因为不需要重新申请内存。

**技巧六：一维数组合并**

numpy没有append，因为array的数据结构是块状，改变元素个数需要重新申请内存并复制，所以应当尽量减小数组合并的次数。

- concatenate是比较快速的函数
- r_[]
- 转化成list再合并是非常慢的

**技巧七：避免花式索引**

- 花式索引(fancy indexing)即用narray作为index取出一个小数组。因为会效率低而且占内存，不适合大量调用。如果需要可以用布尔掩模或者使用take、compress替代。

**技巧八：避免narray.T转置数组**

- 转置涉及到拷贝，非常耗时。一个例子是：在向量或者矩阵乘法中需要用到转置，这种场合可以事先将矩阵定义为良好的形状，或者使用**einsum**替代**dot**，付出较小的代价。