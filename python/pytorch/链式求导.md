# 链式求导的计算

在网络求导的时候，其实在网络forward'的时候是保存了输出的结果和公式的，然后在backward的时候调出用于计算。

在手写反传的时候有时候会混淆了$\frac{df}{dx}$和$\frac{\partial f}{\partial x}$的写法，然后自己就容易搞乱了，还以为自己写错了。



举一个归一化的例子：归一化是对矩阵做偏移和缩放的操作。
$$
f = \frac{x-E[x]}{\sqrt{Var[x]}}
$$
这时候简写成
$$
f = \frac{x-f_1(x)}{f_2(x)}
$$
求导：
$$
\frac{df}{dx} = \frac{\partial f}{\partial x} + \frac{\partial f_1}{\partial x}\frac{df_1}{dx} + \frac{\partial f_2}{\partial x}\frac{df_2}{dx}\\
= \frac{1}{f_2} + -\frac{f_1}{f_2}\frac{df_1}{dx} + (-\frac{x - f_1}{f_2^2})\frac{df_2}{dx}\\
= \frac{1}{f_2} + -\frac{f_1}{f_2}\frac{df_1}{dx} + \frac{f}{-f_2}\frac{df_2}{dx}\\
$$
这时候就只需要在forward的时候保存$f,f_1,f_2$的值用于反传，然后按照以上规则计算$\frac{df_1}{dx}$和$\frac{df_2}{dx}$就行。



对于期望$E[x]$来说，导数就是1
$$
E[{\bf x}] = \sum_i x_i \\
f_1 = x+a+b+c+...+i\\
\frac{df_1}{x} = 1
$$
